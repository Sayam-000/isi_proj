{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBciFg1XrviE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from skimage import io, transform\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHqDZqBfr_jR"
   },
   "source": [
    "**Multi Label Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT5kQbzQsHk4"
   },
   "source": [
    "Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u9H_OQtVsJ-Y"
   },
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,self.annotations.iloc[idx, 1])\n",
    "        image = io.imread(img_name)\n",
    "        labels = self.annotations.iloc[idx, 2]\n",
    "\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "#         print(\"sample\",sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bhwUYY-JE0Hh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      4\u001b[0m label_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(classes)\n\u001b[1;32m----> 8\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelDataset\u001b[49m(csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/train/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/train/\u001b[39m\u001b[38;5;124m'\u001b[39m,transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()]))\n\u001b[0;32m      9\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     10\u001b[0m testset \u001b[38;5;241m=\u001b[39m MultiLabelDataset(csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/test/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/test/\u001b[39m\u001b[38;5;124m'\u001b[39m,transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelDataset' is not defined"
     ]
    }
   ],
   "source": [
    "classes = {'T-Shirt','Trouser','PullOver','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot'}\n",
    "\n",
    "batch_size=4\n",
    "label_count=len(classes)\n",
    "\n",
    "\n",
    "\n",
    "trainset = MultiLabelDataset(csv_file = '/home/dnn4/pythonCodeArea/sayam/train/labels.csv',root_dir = '/home/dnn4/pythonCodeArea/sayam/train/',transform = transforms.Compose([transforms.ToTensor()]))\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=10)\n",
    "testset = MultiLabelDataset(csv_file = '/home/dnn4/pythonCodeArea/sayam/test/labels.csv', root_dir = '/home/dnn4/pythonCodeArea/sayam/test/',transform = transforms.Compose([transforms.ToTensor()]))\n",
    "testloader = DataLoader(trainset, batch_size=batch_size,shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtestloader\u001b[49m))\n\u001b[0;32m      2\u001b[0m img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "img=next(iter(testloader))\n",
    "img['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffpergPL5TXR"
   },
   "source": [
    "Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XDtyzJHE5Wsc"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.f1 = nn.Linear(1600, 120)\n",
    "        self.f2 = nn.Linear(120, 84)\n",
    "        self.f3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"x\",(x.shape))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "#         print(\"x.shape\",x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print(\"x.shape\",x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten dimensions\n",
    "#         print(\"x.shape\",x.shape)\n",
    "        x = F.relu(self.f1(x))\n",
    "#         print(\"x.shape\",x.shape)\n",
    "        x = F.relu(self.f2(x))\n",
    "#         print(\"x.shape\",x.shape)\n",
    "        x = self.f3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMI3cCNu5a9E"
   },
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eC9OZhMO6iuU"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimiser = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1jLG0KL7kHI"
   },
   "source": [
    "Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tHFvY27E7sEW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 1 loss:  1449.5404100716114 accuracy: 17\n",
      "epoch loss: 2 loss:  499.8605490550399 accuracy: 21\n",
      "epoch loss: 3 loss:  481.31152311712503 accuracy: 22\n",
      "epoch loss: 4 loss:  478.2486839145422 accuracy: 23\n",
      "epoch loss: 5 loss:  476.18843922764063 accuracy: 23\n",
      "epoch loss: 6 loss:  473.457547262311 accuracy: 24\n",
      "epoch loss: 7 loss:  469.95835088938475 accuracy: 24\n",
      "epoch loss: 8 loss:  465.5821599662304 accuracy: 24\n",
      "epoch loss: 9 loss:  460.0684664323926 accuracy: 24\n",
      "epoch loss: 10 loss:  453.31169368326664 accuracy: 24\n",
      "epoch loss: 11 loss:  446.7192024886608 accuracy: 24\n",
      "epoch loss: 12 loss:  441.4691327661276 accuracy: 24\n",
      "epoch loss: 13 loss:  436.24108296632767 accuracy: 24\n",
      "epoch loss: 14 loss:  431.02012449130416 accuracy: 24\n",
      "epoch loss: 15 loss:  425.23686495423317 accuracy: 24\n",
      "epoch loss: 16 loss:  419.61384427919984 accuracy: 24\n",
      "epoch loss: 17 loss:  413.4377732872963 accuracy: 25\n",
      "epoch loss: 18 loss:  405.88129659742117 accuracy: 25\n",
      "epoch loss: 19 loss:  398.5641698203981 accuracy: 25\n",
      "epoch loss: 20 loss:  393.2149595990777 accuracy: 25\n",
      "epoch loss: 21 loss:  386.96322943270206 accuracy: 25\n",
      "epoch loss: 22 loss:  381.9171604439616 accuracy: 25\n",
      "epoch loss: 23 loss:  376.21361775510013 accuracy: 25\n",
      "epoch loss: 24 loss:  371.2127289697528 accuracy: 25\n",
      "epoch loss: 25 loss:  366.45917258411646 accuracy: 25\n",
      "epoch loss: 26 loss:  361.0664956048131 accuracy: 25\n",
      "epoch loss: 27 loss:  356.88308185711503 accuracy: 25\n",
      "epoch loss: 28 loss:  353.18164955824614 accuracy: 25\n",
      "epoch loss: 29 loss:  348.7310648486018 accuracy: 25\n",
      "epoch loss: 30 loss:  345.5333659462631 accuracy: 25\n",
      "epoch loss: 31 loss:  341.702044762671 accuracy: 25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(label_count):\n\u001b[0;32m---> 55\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m m[i][j]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m multi_hot_GT[i][j]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m                     correct\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m#if i % 100 == 99:    # print every 2000th mini-batche\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#     print(f'{epoch + 1} epoch loss: {loss_at_iteration.3f} accuracy: {100 * correct // total}')\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total=0\n",
    "correct=0\n",
    "for epoch in range(100):  # Iterations over the dataset\n",
    "    loss_at_iteration = 0.0\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels= data['image'], data['labels']\n",
    "#         print('labels',labels)\n",
    "#         for t in range(len(labels)):\n",
    "#             labels[t]=list(labels[t])\n",
    "#         print('labels',labels)\n",
    "            \n",
    "        m=torch.zeros([batch_size,label_count])\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if labels[i][j]!='[' and labels[i][j]!=']' and labels[i][j]!=',' and labels[i][j]!=' ':\n",
    "                    m[i][j]=int(labels[i][j]) \n",
    "                    \n",
    "        inputs = inputs.cuda(), \n",
    "#         labels = torch.Tensor(labels)\n",
    "        m = m.cuda()\n",
    "\n",
    "        # set the parameter gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward backward and optimise\n",
    "        outputs = net(inputs[0])\n",
    "        \n",
    "#         print(type(outputs),type(labels))\n",
    "        loss = criterion(outputs, m)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # print stats\n",
    "        loss_at_iteration += loss.item()\n",
    "\n",
    "        \n",
    "        predicted=torch.topk(outputs, 4)\n",
    "        predicted_indices = predicted[1]\n",
    "        \n",
    "        multi_hot_GT=torch.zeros([batch_size,label_count]).cuda()\n",
    "        for i in range(batch_size):\n",
    "            for p in range(len(predicted_indices[i])):\n",
    "                multi_hot_GT[i][predicted_indices[i]]=1\n",
    "\n",
    "#         print(\"m1\",m1)#,predicted)\n",
    "#         print(\"multi_hot_GT\",multi_hot_GT)\n",
    "        \n",
    "        total += m.shape[0]*4\n",
    "#         print(\"(multi_hot_GT == m1).sum().item()\",(multi_hot_GT == m1).sum().item())\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if m[i][j]==1 and multi_hot_GT[i][j]==1:\n",
    "                    correct+=1 \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #if i % 100 == 99:    # print every 2000th mini-batche\n",
    "#     print(f'{epoch + 1} epoch loss: {loss_at_iteration.3f} accuracy: {100 * correct // total}')\n",
    "    print('epoch loss:', epoch + 1,'loss: ',loss_at_iteration, 'accuracy:', 100 * correct // total)\n",
    "\n",
    "    loss_at_iteration = 0.0\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrMcBuVI8kT0"
   },
   "outputs": [],
   "source": [
    "#To Save The Network\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPx41Dim8lXt"
   },
   "source": [
    "Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHSxwzo78pT2"
   },
   "outputs": [],
   "source": [
    "#function to show image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "data_iter = iter(testloader)\n",
    "images, labels = data_iter.next()['image'] , data_iter.next()['labels']\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print('Ground Truth: ', ' '.join(f'{classes[labels[j][0]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEuTBOl984Z6"
   },
   "outputs": [],
   "source": [
    "#Reload the saved Model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net = net.cuda()\n",
    "images, m = images.cuda(), m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xurWJPSj88LA"
   },
   "outputs": [],
   "source": [
    "# outputs = net(images[0])\n",
    "# _,predicted = torch.sort(outputs,1)\n",
    "# predicted = predicted[-4:]\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data['image'],data['labels']\n",
    "        m1=torch.zeros([batch_size,label_count])\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if labels[i][j]!='[' and labels[i][j]!=']' and labels[i][j]!=',' and labels[i][j]!=' ':\n",
    "                    m1[i][j]=int(labels[i][j]) \n",
    "                    \n",
    "        images, m1 = images.cuda(), m1.cuda()\n",
    "        \n",
    "        \n",
    "#         print(\"images.shape\",images.shape)\n",
    "        # outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        \n",
    "        \n",
    "        \n",
    "#         _, predicted = torch.sort(outputs.data, 1)\n",
    "        predicted=torch.topk(outputs, 4)\n",
    "        predicted_indices = predicted[1]\n",
    "        \n",
    "        multi_hot_GT=torch.zeros([batch_size,label_count]).cuda()\n",
    "        for i in range(batch_size):\n",
    "            for p in range(len(predicted_indices[i])):\n",
    "                multi_hot_GT[i][predicted_indices[i]]=1\n",
    "\n",
    "#         print(\"m1\",m1)#,predicted)\n",
    "#         print(\"multi_hot_GT\",multi_hot_GT)\n",
    "        \n",
    "        total += m1.shape[0]*4\n",
    "#         print(\"(multi_hot_GT == m1).sum().item()\",(multi_hot_GT == m1).sum().item())\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if m1[i][j]==1 and multi_hot_GT[i][j]==1:\n",
    "                    correct+=1\n",
    "        \n",
    "        \n",
    "#         correct += (multi_hot_GT == m1).sum().item()\n",
    "        \n",
    "        \n",
    "\n",
    "print(f'Accuracy on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_func(multihot_batch):\n",
    "    print(multihot_batch.shape)\n",
    "#     multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1]])\n",
    "    #multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1], [0,0,0,1]])\n",
    "    vnon = (multihot_batch == torch.tensor(1)).nonzero(as_tuple=False).cuda()\n",
    "    v0 = vnon[:,0].cuda()\n",
    "    v1 = vnon[:,1].cuda()\n",
    "\n",
    "    # 0-based index -> 1-based index\n",
    "    split_ind = ((torch.roll(v0, -1, 0) - v0) == 1).nonzero(as_tuple=False)[:,0] + 1\n",
    "    split_ind = split_ind.cuda()\n",
    "    print(split_ind.shape)\n",
    "    # the first index is excatly the split size of the first split\n",
    "    # the other splits(apart from the last one) can be obtained by this\n",
    "    split_size = torch.cat([split_ind[0].view(1),(torch.roll(split_ind, -1, 0) - split_ind)[:-1]])\n",
    "    # add the final split size\n",
    "    split_size=split_size.cuda()\n",
    "    \n",
    "    final_size = torch.tensor([torch.numel(v1) - torch.sum(split_size)])\n",
    "    \n",
    "    final_size=final_size.cuda()\n",
    "    split_size = torch.cat([split_size, final_size])\n",
    "    \n",
    "    return torch.split(v1, split_size.tolist())\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1]])\n",
    "multihot_batch.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
