{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBciFg1XrviE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from skimage import io, transform\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torchvision.models as tmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHqDZqBfr_jR"
   },
   "source": [
    "**Multi Label Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT5kQbzQsHk4"
   },
   "source": [
    "Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u9H_OQtVsJ-Y"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMultiLabelDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, csv_file, root_dir, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir \u001b[38;5;241m=\u001b[39m root_dir\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,self.annotations.iloc[idx, 1])\n",
    "        image = io.imread(img_name)\n",
    "        labels = self.annotations.iloc[idx, 2]\n",
    "\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "#         print(\"sample\",sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bhwUYY-JE0Hh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      4\u001b[0m label_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(classes)\n\u001b[1;32m----> 7\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelDataset\u001b[49m(csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/train/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/train/\u001b[39m\u001b[38;5;124m'\u001b[39m,transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()]))\n\u001b[0;32m      8\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      9\u001b[0m testset \u001b[38;5;241m=\u001b[39m MultiLabelDataset(csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/test/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/dnn4/pythonCodeArea/sayam/test/\u001b[39m\u001b[38;5;124m'\u001b[39m,transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelDataset' is not defined"
     ]
    }
   ],
   "source": [
    "classes = {'T-Shirt','Trouser','PullOver','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot'}\n",
    "\n",
    "batch_size=4\n",
    "label_count=len(classes)\n",
    "\n",
    "\n",
    "trainset = MultiLabelDataset(csv_file = '/home/dnn4/pythonCodeArea/sayam/train/labels.csv',root_dir = '/home/dnn4/pythonCodeArea/sayam/train/',transform = transforms.Compose([transforms.ToTensor()]))\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=10)\n",
    "testset = MultiLabelDataset(csv_file = '/home/dnn4/pythonCodeArea/sayam/test/labels.csv', root_dir = '/home/dnn4/pythonCodeArea/sayam/test/',transform = transforms.Compose([transforms.ToTensor()]))\n",
    "testloader = DataLoader(trainset, batch_size=batch_size,shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtestloader\u001b[49m))\n\u001b[0;32m      2\u001b[0m img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "img=next(iter(testloader))\n",
    "img['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffpergPL5TXR"
   },
   "source": [
    "Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XDtyzJHE5Wsc"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        res_state=tmodels.resnet18(pretrained=True)\n",
    "        self.cnn=nn.Sequential(*list(res_state.children())[:-3])\n",
    "        \n",
    "        self.f1 = nn.Linear(256, 10)\n",
    "        self.f2 = nn.Linear(256, 10)\n",
    "        self.f3 = nn.Linear(256, 10)\n",
    "        self.f4 = nn.Linear(256, 10)\n",
    "        \n",
    "        self.pooling_cnn1=nn.Conv2d(256, 256, kernel_size=(1,1))\n",
    "        self.pooling_cnn2=nn.Conv2d(256, 256, kernel_size=(1,1))\n",
    "        self.pooling_cnn3=nn.Conv2d(256, 256, kernel_size=(1,1))\n",
    "        self.pooling_cnn4=nn.Conv2d(256, 256, kernel_size=(1,1))\n",
    "        \n",
    "        self.pool1=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.pool2=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.pool3=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.pool4=nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.cnn(x)\n",
    "        \n",
    "        x1=self.pooling_cnn1(x)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x1=self.pool1(x1)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x1=torch.squeeze(x1)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x1=self.f1(x1)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        \n",
    "        x2=self.pooling_cnn2(x)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x2=self.pool2(x2)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x2=torch.squeeze(x2)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x2=self.f2(x2)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "\n",
    "        x3=self.pooling_cnn3(x)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x3=self.pool3(x3)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x3=torch.squeeze(x3)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x3=self.f3(x3)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "\n",
    "        x4=self.pooling_cnn4(x)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x4=self.pool4(x4)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x4=torch.squeeze(x4)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "        x4=self.f1(x4)\n",
    "#         print(\"x1.shape\",x1.shape)\n",
    "\n",
    "        x1=(x1+x2+x3+x4)/4\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(4,1,28,128)\n",
    "\n",
    "x=x.repeat(1, 3, 1,1)\n",
    "x=x.cuda()\n",
    "y=net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMI3cCNu5a9E"
   },
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eC9OZhMO6iuU"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimiser = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# optimiser = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1jLG0KL7kHI"
   },
   "source": [
    "Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tHFvY27E7sEW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrainloader\u001b[49m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# get the inputs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     inputs, labels\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # Iterations over the dataset\n",
    "    loss_at_iteration = 0.0\n",
    "    total=0.0\n",
    "    correct=0\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels= data['image'], data['labels']\n",
    "        inputs=inputs.repeat(1, 3, 1,1)\n",
    "#         print('labels',labels)\n",
    "#         for t in range(len(labels)):\n",
    "#             labels[t]=list(labels[t])\n",
    "#         print('labels',labels)\n",
    "            \n",
    "        m=torch.zeros([batch_size,label_count])#,dtype=torch.long\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if labels[i][j]!='[' and labels[i][j]!=']' and labels[i][j]!=',' and labels[i][j]!=' ':\n",
    "                    m[i][j]=int(labels[i][j]) \n",
    "                    \n",
    "        inputs = inputs.cuda(), \n",
    "#         labels = torch.Tensor(labels)\n",
    "        m = m.cuda()\n",
    "\n",
    "        # set the parameter gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward backward and optimise\n",
    "        outputs = net(inputs[0])\n",
    "        \n",
    "#         print(type(outputs),type(labels))\n",
    "        loss = criterion(outputs, m)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        predicted=torch.topk(outputs, 4)\n",
    "        predicted_indices = predicted[1]        \n",
    "\n",
    "        total += m.shape[0]*4\n",
    "        \n",
    "        multi_hot_GT=torch.zeros([batch_size,label_count]).cuda()\n",
    "        for i in range(batch_size):\n",
    "            for p in range(len(predicted_indices[i])):\n",
    "                multi_hot_GT[i][predicted_indices[i]]=1        \n",
    "        \n",
    "#         print(\"(multi_hot_GT == m1).sum().item()\",(multi_hot_GT == m1).sum().item())\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if m[i][j]==1 and multi_hot_GT[i][j]==1:\n",
    "                    correct+=1 \n",
    "        \n",
    "        \n",
    "        #if i % 100 == 99:    # print every 2000th mini-batche\n",
    "#     print(f'{epoch + 1} epoch loss: {loss_at_iteration.3f} accuracy: {100 * correct // total}')\n",
    "    print('epoch:', epoch + 1,'loss: ',loss_at_iteration, 'accuracy:', 100 * correct // total)\n",
    "\n",
    "    loss_at_iteration = 0.0\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrMcBuVI8kT0"
   },
   "outputs": [],
   "source": [
    "#To Save The Network\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPx41Dim8lXt"
   },
   "source": [
    "Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHSxwzo78pT2"
   },
   "outputs": [],
   "source": [
    "#function to show image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "data_iter = iter(testloader)\n",
    "images, labels = data_iter.next()['image'] , data_iter.next()['labels']\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print('Ground Truth: ', ' '.join(f'{classes[labels[j][0]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEuTBOl984Z6"
   },
   "outputs": [],
   "source": [
    "#Reload the saved Model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net = net.cuda()\n",
    "images, m = images.cuda(), m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xurWJPSj88LA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the 10000 test images: 25 %\n"
     ]
    }
   ],
   "source": [
    "# outputs = net(images[0])\n",
    "# _,predicted = torch.sort(outputs,1)\n",
    "# predicted = predicted[-4:]\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data['image'],data['labels']\n",
    "        images=images.repeat(1, 3, 1,1)\n",
    "        \n",
    "        \n",
    "        m1=torch.zeros([batch_size,label_count])\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if labels[i][j]!='[' and labels[i][j]!=']' and labels[i][j]!=',' and labels[i][j]!=' ':\n",
    "                    m1[i][j]=int(labels[i][j]) \n",
    "                    \n",
    "        images, m1 = images.cuda(), m1.cuda()\n",
    "        \n",
    "        \n",
    "#         print(\"images.shape\",images.shape)\n",
    "        # outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        \n",
    "        \n",
    "        \n",
    "#         _, predicted = torch.sort(outputs.data, 1)\n",
    "        predicted=torch.topk(outputs, 4)\n",
    "        predicted_indices = predicted[1]\n",
    "        \n",
    "        multi_hot_GT=torch.zeros([batch_size,label_count]).cuda()\n",
    "        for i in range(batch_size):\n",
    "            for p in range(len(predicted_indices[i])):\n",
    "                multi_hot_GT[i][predicted_indices[i]]=1\n",
    "\n",
    "#         print(\"m1\",m1)#,predicted)\n",
    "#         print(\"multi_hot_GT\",multi_hot_GT)\n",
    "        \n",
    "        total += m1.shape[0]*4\n",
    "#         print(\"(multi_hot_GT == m1).sum().item()\",(multi_hot_GT == m1).sum().item())\n",
    "        for i in range(batch_size):\n",
    "            for j in range(label_count):\n",
    "                if m1[i][j]==1 and multi_hot_GT[i][j]==1:\n",
    "                    correct+=1\n",
    "        \n",
    "        \n",
    "#         correct += (multi_hot_GT == m1).sum().item()\n",
    "      \n",
    "\n",
    "print(f'Accuracy on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_func(multihot_batch):\n",
    "    print(multihot_batch.shape)\n",
    "#     multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1]])\n",
    "    #multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1], [0,0,0,1]])\n",
    "    vnon = (multihot_batch == torch.tensor(1)).nonzero(as_tuple=False).cuda()\n",
    "    v0 = vnon[:,0].cuda()\n",
    "    v1 = vnon[:,1].cuda()\n",
    "\n",
    "    # 0-based index -> 1-based index\n",
    "    split_ind = ((torch.roll(v0, -1, 0) - v0) == 1).nonzero(as_tuple=False)[:,0] + 1\n",
    "    split_ind = split_ind.cuda()\n",
    "    print(split_ind.shape)\n",
    "    # the first index is excatly the split size of the first split\n",
    "    # the other splits(apart from the last one) can be obtained by this\n",
    "    split_size = torch.cat([split_ind[0].view(1),(torch.roll(split_ind, -1, 0) - split_ind)[:-1]])\n",
    "    # add the final split size\n",
    "    split_size=split_size.cuda()\n",
    "    \n",
    "    final_size = torch.tensor([torch.numel(v1) - torch.sum(split_size)])\n",
    "    \n",
    "    final_size=final_size.cuda()\n",
    "    split_size = torch.cat([split_size, final_size])\n",
    "    \n",
    "    return torch.split(v1, split_size.tolist())\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_batch = torch.tensor([[0,1,0,1], [0,0,0,1], [0,0,1,1]])\n",
    "multihot_batch.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
